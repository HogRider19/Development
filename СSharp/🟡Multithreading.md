Одним из ключевых аспектов в программировании является многопоточность. Ключевым понятием при работе с многопоточностью является поток. Поток представляет некоторую часть выполняемого кода программы. При выполнении нашей программы каждому потоку выделяется определенный квант времени. Мы можем выделить в приложении несколько потоков, которые будут выполнять различные задачи одновременно на разных ядрах. 

>[!info] Важно
>В современных приложениях, как правило, используются более высокоуровневые абстракции такие как: ThraedPool, Task, async/await, а прямая работа с классом Thread нужна лишь в специфичных сценариях, к примеру необходим заранее выделенный долгоживущий поток, требуется явно задать стек, уникальное имя или приоритет. 

Для мультиплатформенной работы с потоками, стандартной библиотекой предоставляется класс обертка `System.Threading.Thread`. Также есть специальный статический метод `Thread.CurrentThread` позволяющий получить экземпляр текущего потока.

```c#
Thread thread = new Thread(() => {});
thread.Start();
```

---

Cоз­да­ние по­то­ка является очень до­ро­гой опе­ра­цией. Для создания потока нужно выполнять системный вызов, а это пре­о­до­ле­ние барь­е­ра меж­ду сло­ем прик­лад­но­го `ПО` и сло­ем опе­ра­ци­он­ной сис­те­мы. Плюс соз­да­ние доп­ол­нит­ель­ных струк­тур дан­ных со сто­ро­ны `NET`. В итоге что­бы что-то ис­пол­нить пар­ал­лель­но, для на­ча­ла придётся пот­ра­тить мно­го вре­ме­ни.

Именно для решения этой проблемы была придумана концепция пула потоков `ThreadPool`. Пул потоков решает несколько задач: с одной стороны он абстрагирует создание потока; также он обеспечивает переиспользование потоков; повышает производительность системы, исключая издержки на создание новых потоков, используя созданные.

Реализация `ThreadPool` в стандартной библиотеке представлена статическим классом
без возможности повлиять на реализацию. Таким образом пользовательские пулы потоков, создается посредством отдельных классов, без серьезной поддержки инфраструктуры. 

Пул потоков представляет контейнер который хранит и управляет созданными потоками. Этот контейнер, при старте передаёт потоку метод исполнения, который внутри себя в бесконечном цикле разбирает очередь поставленных пулу потоков задач и исполняет
их. Но возникает проблема: ожидание от оборудования происходит в потоке, который инициировал это ожидание. То есть если мы будем ожидать в пуле потоков, мы снизим
его уровень параллелизма. Для этого в `TreadPool` создали дополнительны пул ожидания.
И когда код, работающий в основном пуле решается встать в блокировку, сделать он это должен специальным образом: перепланировавшись на внутренний пул ожидания.

Пул потоков внутри себя в зависимости от некоторых метрик создаёт некоторое количество рабочих потоков. Каждый из которых содержит цикл выборки делегатов на исполнение.

```c#
// Установкак минимального и максимального число рабочих потоков
ThreadPool.SetMinThreads(workerThreads: 10, completionPortThreads: 5);
ThreadPool.SetMaxThreads(workerThreads: 50, completionPortThreads: 25);

// Получение текущих значений
ThreadPool.GetMaxThreads(out int maxWorker, out int maxIOC);
ThreadPool.GetMinThreads(out int minWorker, out int minIOC);
ThreadPool.GetAvailableThreads(out int availWorker, out int availIOC);

// Задача без передачи состояния
ThreadPool.QueueUserWorkItem(() => {});

// Задача с передачей состояния
ThreadPool.QueueUserWorkItem((state) => {}, someState);

// Регистрация в пул ожидания
ThreadPool.RegisterWaitForSingleObject(
	waitObject: autoEvent,
	callBack: WaitOrTimerCallbackMethod,
	state: someState,
	millisecondsTimeOutInterval: 5000,
	executeOnlyOnce: false
);
```

Оптимальное число потоков для выполнения чисто вычислительных задач соответствует количеству физических ядер процессора. Если вы увеличиваете число потоков сверх этого, каждый поток вынужден поочерёдно занимать одно и то же ядро, что приводит к росту времени выполнения: при удвоении числа потоков на каждом ядре каждый поток
получает лишь половину ресурсов и отрабатывает дольше, чем при равном числе.

---

При конкурентом выполнении потоков с доступом к общим ресурсам, могут возникнуть некоторые аномалии при выполнении программы. Вот несколько основных из них:

**==Deadlock==**. Представляет ситуацию при которой потоки взаимно блокируют друг друга.
Такое поведение возможно при неправильной настройки системы синхронизации. 

```c#
lock (a) { lock (b) { … } } //Thread_1
lock (b) { lock (a) { … } } //Thread_2
```

**==RaceCondition==**. Представляет ситуацию, в которой поведение и результат вычислений, выполняемых программой, зависит от работы планировщика потоков. Возникает когда потоки имеют доступ к общему ресурсу без синхронизации или с плохой настройкой.

**==BusyWait==**. Проблема, при которой программа потребляет ресурсы процессора не для вычислений, а для ожидания. Возникает при реализации ожидания через бесконечную проверку условия в цикле, а не через механизм уведомлений или механизм таймеров.

**==ThreadStarvation==**. Проблема, при которой в программе слишком много одновременно работающих потоков. Процессор тратит много времени на переключение контекстов.

---

**==Monitor==**. Монитор представляет критическую секцию, то есть секцию которую 
нельзя выполнить пока предыдущий поток системы не заверши ее выполнение.

Код, написанный между вызовами `Monitor.Enter`, `Monitor.Exit` на одном
ресурсе может быть выполнен в один момент времени лишь одним потоком.

Оператор `lock (locker)` является синтаксическим сахаром вызова методов
`Monitor.Enter` и `Monitor.Exit` обернутых в секцию обработки исключений.

```c#
bool acquiredLock = false;
try
{
	Monitor.Enter(locker, ref acquiredLock);
	// Some code
}
finally
{
	if (acquiredLock) Monitor.Exit(locker);
}
```

В `C#` каждый объект в памяти снабжается заголовком, в котором, помимо указателя на таблицу методов, хранится индекс в таблице синхронизации `SyncBlockIndex`. Именно 
этот индекс позволяет в нужный момент обратиться к отдельной структуре `SyncBlock`, 
где содержится подробная информация о статусе блокировки: владелец, счётчики
рекурсии, ждущие потоки, а также примитивы ядра для ожидания и пробуждения.

При первом захвате монитора `CLR` старается использовать так называемую тонкую блокировку `thinLock`. В этом случае информация о блокировке хранится непосредственно в заголовке объекта. Вместо того, чтобы создавать дополнительные структуры или делать системный вызов, операция `Monitor.Enter` выполняется с помощью простой атомарной операции. Если объект ещё не заблокирован, поток сразу получает доступ к ресурсу, не тратя время на дополнительные накладные расходы. Это особенно эффективно в
случаях, когда нет конкуренции за ресурс, и блокировка используется редко.

Когда несколько потоков одновременно пытаются захватить один и тот же монитор или когда поток пытается зайти в уже захваченный монитор несколько раз, `CLR` переключается на более сложную толстую блокировку `fatlock`. В этом случае создаётся или используется специальная структура данных `SyncBlock`, которая содержит более сложную информацию, такую как критическая секция операционной системы, очередь потоков, которые ждут своей очереди на захват монитора, и события для разблокировки. Когда поток вызывает `Enter` в этом режиме, он сначала захватывает критическую секцию, проверяет, является ли он владельцем монитора, если поток является другим владельцем, то он помещается в
очередь и блокируется до тех пор, пока не получит доступ к монитору.

Для повышения производительности `CLR` перед тем, как падать в системные ожидания, выполняет короткие спин ожидания: несколько быстрых циклов, проверяя, не освободится ли монитор моментально. `SyncBlock`при этом хранятся в глобальной хеш-таблице, и их количество регулируется `CLR`, чтобы экономить память. Такой гибрид тонких и толстых блокировок позволяет максимально упростить работу в `uncontended` сценариях и при этом сохранять полную функциональность и корректность при высококонкурентном доступе.

**==Mutex==**. Мьютекс как и `Monitor`, предоставляет монопольный доступ к общему ресурсу только одному потоку. Если поток получает мьютекс, второй поток, который хочет получить этот мьютекс, приостанавливается до тех пор, пока первый его не высвободит обратно. 

Работает несколько медленнее чем `Мonitor`, но дает доступ из внешних процессов, так
как реализован на уровне операционной системы. Изначально мьютекс свободен.

```c#
Mutex mutexObj = new();

Thread thread1 = new(SafeAction);
Thread thread2 = new(SafeAction);
thread1.Start(); thread2.Start();
 
void SafeAction()
{
    mutexObj.WaitOne();
	// Some Action
    mutexObj.ReleaseMutex();
}
```

**==Semaphore==**. Семафоры позволяют ограничить количество потоков, которые имеют
доступ к некоторой критической секции. Механизм похож на работу `Mutex`.

```c#
Semaphore sem = new Semaphore(initThreadCount, maxThreadCount);

Thread thread1 = new(SafeAction);
Thread thread2 = new(SafeAction);
thread1.Start(); thread2.Start();
 
void SafeAction()
{
	sem.WaitOne();
	// Some Action
	sem.Release();
}
```

[[СSharp/🟡Base|🟡Base]]